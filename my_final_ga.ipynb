{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qqXnrz8JFPUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c24aab1-4540-4dae-8598-885e4a22091a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deap\n",
            "  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 32.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.3.1\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "!pip install deap\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np \n",
        "import math\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from deap import algorithms, base, creator, tools\n",
        "from nltk import word_tokenize\n",
        "import re, string\n",
        "import random\n",
        "import statistics \n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "orabcQu0FPUZ"
      },
      "outputs": [],
      "source": [
        "dict_freq = {}  # frequency map for words in list\n",
        "dict_paired_freq = {}\n",
        "\n",
        "path = 'train-data.dat'\n",
        "clean_files = []\n",
        "df = pd.DataFrame()\n",
        "\n",
        "file = open(path).readlines()\n",
        "len(file)\n",
        "\n",
        "#clear data\n",
        "clear_file=[]\n",
        "for i in range(len(file)):\n",
        "    x=re.sub('<.*?>','',file[i])\n",
        "    clear_file.append(x)\n",
        "\n",
        "clear_file=clear_file[:]\n",
        "\n",
        "#perasma tou clear keimenou sto words string\n",
        "words = ''\n",
        "for line in clear_file:\n",
        "    words += line\n",
        "\n",
        "\n",
        "tokenized_words = word_tokenize(words) # list of all words in new dictionary\n",
        "WORD_LIST = list(set(tokenized_words)) # create a set out of words so there are no repeats in word list and make list again\n",
        "dictionary_size = len(WORD_LIST) #6853\n",
        "\n",
        "\n",
        "#Dhmiourgia dictionary lekseis kai suxnotitas emfanisi tis lekseis se olo to keimeno\n",
        "for word in tokenized_words: #gia kathe word sto lista leksewn olou tou keimenou\n",
        "    if word not in dict_freq: \n",
        "        dict_freq[word] = 1\n",
        "    else:\n",
        "        dict_freq[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JHVW15MFPUb",
        "outputId": "15f8dd2b-e280-41d5-f60c-2230c7ab9a07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8520"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#TF = (Frequency of the word in the sentence) / (Total number of words in the sentence)\n",
        "def computeTF(wordDict,bow):\n",
        "    tfDict={}\n",
        "    bowCount=len(bow)\n",
        "    for word,count in wordDict.items():\n",
        "        tfDict[word] = count/float(bowCount)\n",
        "    return tfDict\n",
        "\n",
        "tf=computeTF(dict_freq,tokenized_words)\n",
        "\n",
        "#IDF: log((Total number of sentences (documents))/(Number of sentences (documents) containing the word))\n",
        "def computeIDF(docList):\n",
        "    idfDict = {}\n",
        "    N = len(docList)\n",
        "    \n",
        "    idfDict = dict.fromkeys(dict_freq,0)\n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
        "        \n",
        "    return idfDict\n",
        "\n",
        "idf=computeIDF(dict_freq)\n",
        "len(idf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R1IAnJbJFPUc"
      },
      "outputs": [],
      "source": [
        "#FINAL TF-IDF\n",
        "def computeDFIDF(tfbow,idfs):\n",
        "    tfidf={}\n",
        "    for word,val in tfbow.items():\n",
        "        tfidf[word] = val*idfs[word]\n",
        "\n",
        "    return tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NoLp9o8vFPUd"
      },
      "outputs": [],
      "source": [
        "#final TF-IDF\n",
        "Tf_idf=computeDFIDF(tf,idf)\n",
        "#Apothikeusi mono ton timwn\n",
        "new_list = list(Tf_idf.values())\n",
        "len(new_list)\n",
        "tf_idf_Xtrain = np.asarray(new_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t7W7Pb_-FPUd"
      },
      "outputs": [],
      "source": [
        "#Create a FitnessMax class \n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "#Create an Individual class \n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "def getFitness(individual):\n",
        "    counter = 0\n",
        "    fitness = 0\n",
        "\n",
        "    #gia kathe thesi sto indi\n",
        "    for word_index in individual:\n",
        "        #vale sto string thn antistoixi leksi\n",
        "        if new_list[word_index] <= 1:\n",
        "            fitness += new_list[word_index]\n",
        "        \n",
        "        else:\n",
        "            fitness -=20\n",
        "    \n",
        "    return fitness,\n",
        "\n",
        "        \n",
        "#The toolbox is a container for functions with their arguments\n",
        "toolbox = base.Toolbox()\n",
        "# Attribute generator \n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "# Structure initializers\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, len(new_list))\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual) \n",
        "# Register the genetic operators\t\n",
        "toolbox.register(\"evaluate\", getFitness)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jvmuO4gpFPUf",
        "outputId": "8745fb13-b839-48bd-d62d-09ad4903a682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.563007695807405 && Average fitness:15.535766491305697\n",
            "-- Generation 2 --\n",
            " Max fitness:15.57607797069458 && Average fitness:15.55255147589765\n",
            "-- Generation 3 --\n",
            " Max fitness:15.59602733762762 && Average fitness:15.562044622920974\n",
            "-- Generation 4 --\n",
            " Max fitness:15.618728341379038 && Average fitness:15.577900930086733\n",
            "-- Generation 5 --\n",
            " Max fitness:15.62285579660657 && Average fitness:15.593275700809277\n",
            "-- Generation 6 --\n",
            " Max fitness:15.646244709562573 && Average fitness:15.60713707128173\n",
            "-- Generation 7 --\n",
            " Max fitness:15.642117254335046 && Average fitness:15.616767800145961\n",
            "-- Generation 8 --\n",
            " Max fitness:15.64968425558551 && Average fitness:15.631041916141172\n",
            "-- Generation 9 --\n",
            " Max fitness:15.667569894904805 && Average fitness:15.639193640215542\n",
            "-- Generation 10 --\n",
            " Max fitness:15.67100944092775 && Average fitness:15.64734536428991\n",
            "-- Generation 11 --\n",
            " Max fitness:15.67100944092775 && Average fitness:15.653330174369827\n",
            "-- Generation 12 --\n",
            " Max fitness:15.673073168541514 && Average fitness:15.661963434887417\n",
            "-- Generation 13 --\n",
            " Max fitness:15.681328078996572 && Average fitness:15.666744403859303\n",
            "-- Generation 14 --\n",
            " Max fitness:15.683391806610336 && Average fitness:15.672454050257382\n",
            "-- Generation 15 --\n",
            " Max fitness:15.68339180661034 && Average fitness:15.674620964251835\n",
            "-- Generation 16 --\n",
            " Max fitness:15.683391806610336 && Average fitness:15.676409528183768\n",
            "-- Generation 17 --\n",
            " Max fitness:15.683391806610336 && Average fitness:15.677957323894091\n",
            "-- Generation 18 --\n",
            " Max fitness:15.686143443428689 && Average fitness:15.674311405109773\n",
            "-- Generation 19 --\n",
            " Max fitness:15.690270898656218 && Average fitness:15.678094905735009\n",
            "-- Generation 20 --\n",
            " Max fitness:15.690270898656218 && Average fitness:15.679849074206711\n",
            "-- Generation 21 --\n",
            " Max fitness:15.690270898656218 && Average fitness:15.679023583161202\n",
            "-- Generation 22 --\n",
            " Max fitness:15.690270898656218 && Average fitness:15.681465660837485\n",
            "-- Generation 23 --\n",
            " Max fitness:15.690270898656218 && Average fitness:15.686143443428687\n",
            "-- Generation 24 --\n",
            " Max fitness:15.690270898656218 && Average fitness:15.686831352633273\n",
            "-- Generation 25 --\n",
            " Max fitness:15.695774172292921 && Average fitness:15.688379148343596\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 1 COMPLETED ----------------->\n",
            " Max fitness:15.695774172292921 && Average fitness:15.685008393241116\n",
            "2 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.642117254335039 && Average fitness:15.58113410334829\n",
            "-- Generation 2 --\n",
            " Max fitness:15.651747983199275 && Average fitness:15.613362649583252\n",
            "-- Generation 3 --\n",
            " Max fitness:15.675136896155273 && Average fitness:15.631936198107132\n",
            "-- Generation 4 --\n",
            " Max fitness:15.675136896155273 && Average fitness:15.645212845755685\n",
            "-- Generation 5 --\n",
            " Max fitness:15.685455534224095 && Average fitness:15.654843574619914\n",
            "-- Generation 6 --\n",
            " Max fitness:15.686143443428682 && Average fitness:15.666572426558147\n",
            "-- Generation 7 --\n",
            " Max fitness:15.686143443428682 && Average fitness:15.67235086387669\n",
            "-- Generation 8 --\n",
            " Max fitness:15.686143443428682 && Average fitness:15.680605774331747\n",
            "-- Generation 9 --\n",
            " Max fitness:15.686143443428682 && Average fitness:15.684182902195607\n",
            "-- Generation 10 --\n",
            " Max fitness:15.694398353883736 && Average fitness:15.682256756422763\n",
            "-- Generation 11 --\n",
            " Max fitness:15.70196535513421 && Average fitness:15.683185433848953\n",
            "-- Generation 12 --\n",
            " Max fitness:15.69783789990668 && Average fitness:15.685214766002485\n",
            "-- Generation 13 --\n",
            " Max fitness:15.69783789990668 && Average fitness:15.688619916565198\n",
            "-- Generation 14 --\n",
            " Max fitness:15.700589536725035 && Average fitness:15.68800079828107\n",
            "-- Generation 15 --\n",
            " Max fitness:15.704716991952564 && Average fitness:15.693469676457548\n",
            "-- Generation 16 --\n",
            " Max fitness:15.704716991952564 && Average fitness:15.696943617940718\n",
            "-- Generation 17 --\n",
            " Max fitness:15.704716991952564 && Average fitness:15.70072711856595\n",
            "-- Generation 18 --\n",
            " Max fitness:15.717099357635155 && Average fitness:15.70076151402618\n",
            "-- Generation 19 --\n",
            " Max fitness:15.713659811612214 && Average fitness:15.704854573793483\n",
            "-- Generation 20 --\n",
            " Max fitness:15.719850994453505 && Average fitness:15.706367974043577\n",
            "-- Generation 21 --\n",
            " Max fitness:15.719850994453505 && Average fitness:15.707881374293667\n",
            "-- Generation 22 --\n",
            " Max fitness:15.719850994453505 && Average fitness:15.706436764964034\n",
            "-- Generation 23 --\n",
            " Max fitness:15.727417995703977 && Average fitness:15.71424453443611\n",
            "-- Generation 24 --\n",
            " Max fitness:15.727417995703977 && Average fitness:15.719472644390981\n",
            "-- Generation 25 --\n",
            " Max fitness:15.728105904908565 && Average fitness:15.721192417402449\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 2 COMPLETED ----------------->\n",
            " Max fitness:15.732921269340682 && Average fitness:15.722293072129792\n",
            "3 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.571950515467043 && Average fitness:15.540478669357132\n",
            "-- Generation 2 --\n",
            " Max fitness:15.610473430923983 && Average fitness:15.555991021920594\n",
            "-- Generation 3 --\n",
            " Max fitness:15.621479978197407 && Average fitness:15.574770943205854\n",
            "-- Generation 4 --\n",
            " Max fitness:15.620792068992802 && Average fitness:15.594238773695698\n",
            "-- Generation 5 --\n",
            " Max fitness:15.620792068992806 && Average fitness:15.605726857412327\n",
            "-- Generation 6 --\n",
            " Max fitness:15.633174434675393 && Average fitness:15.618453177697205\n",
            "-- Generation 7 --\n",
            " Max fitness:15.669633622518578 && Average fitness:15.623681287652076\n",
            "-- Generation 8 --\n",
            " Max fitness:15.669633622518578 && Average fitness:15.63331201651631\n",
            "-- Generation 9 --\n",
            " Max fitness:15.669633622518578 && Average fitness:15.648996346380923\n",
            "-- Generation 10 --\n",
            " Max fitness:15.669633622518578 && Average fitness:15.66120673476237\n",
            "-- Generation 11 --\n",
            " Max fitness:15.673761077746109 && Average fitness:15.662169807648795\n",
            "-- Generation 12 --\n",
            " Max fitness:15.678576442178226 && Average fitness:15.668292199569631\n",
            "-- Generation 13 --\n",
            " Max fitness:15.684079715814931 && Average fitness:15.670734277245923\n",
            "-- Generation 14 --\n",
            " Max fitness:15.684079715814931 && Average fitness:15.671112627308446\n",
            "-- Generation 15 --\n",
            " Max fitness:15.686831352633286 && Average fitness:15.676581505484922\n",
            "-- Generation 16 --\n",
            " Max fitness:15.68476762501952 && Average fitness:15.67960830598511\n",
            "-- Generation 17 --\n",
            " Max fitness:15.68820717104246 && Average fitness:15.679608305985107\n",
            "-- Generation 18 --\n",
            " Max fitness:15.698525809111283 && Average fitness:15.680880938013592\n",
            "-- Generation 19 --\n",
            " Max fitness:15.697149990702107 && Average fitness:15.68445806587746\n",
            "-- Generation 20 --\n",
            " Max fitness:15.71022026558928 && Average fitness:15.687622448218562\n",
            "-- Generation 21 --\n",
            " Max fitness:15.697149990702107 && Average fitness:15.689823757673244\n",
            "-- Generation 22 --\n",
            " Max fitness:15.69990162752046 && Average fitness:15.688413543803836\n",
            "-- Generation 23 --\n",
            " Max fitness:15.710908174793872 && Average fitness:15.691337157923337\n",
            "-- Generation 24 --\n",
            " Max fitness:15.723290540476457 && Average fitness:15.699007345554495\n",
            "-- Generation 25 --\n",
            " Max fitness:15.710908174793872 && Average fitness:15.700761514026198\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 3 COMPLETED ----------------->\n",
            " Max fitness:15.72191472206728 && Average fitness:15.704269850969595\n",
            "4 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.583644971945038 && Average fitness:15.54126976494241\n",
            "-- Generation 2 --\n",
            " Max fitness:15.590524063990921 && Average fitness:15.564830655199552\n",
            "-- Generation 3 --\n",
            " Max fitness:15.613912976946919 && Average fitness:15.575940388853653\n",
            "-- Generation 4 --\n",
            " Max fitness:15.613912976946919 && Average fitness:15.58756605441119\n",
            "-- Generation 5 --\n",
            " Max fitness:15.613912976946919 && Average fitness:15.596784037752673\n",
            "-- Generation 6 --\n",
            " Max fitness:15.622167887401977 && Average fitness:15.604213457162226\n",
            "-- Generation 7 --\n",
            " Max fitness:15.622167887401977 && Average fitness:15.606793116679432\n",
            "-- Generation 8 --\n",
            " Max fitness:15.631798616266211 && Average fitness:15.614876049833342\n",
            "-- Generation 9 --\n",
            " Max fitness:15.64074143592586 && Average fitness:15.622615028384965\n",
            "-- Generation 10 --\n",
            " Max fitness:15.641429345130456 && Average fitness:15.626708088152261\n",
            "-- Generation 11 --\n",
            " Max fitness:15.641429345130456 && Average fitness:15.632555316391262\n",
            "-- Generation 12 --\n",
            " Max fitness:15.65862707524516 && Average fitness:15.63052598423773\n",
            "-- Generation 13 --\n",
            " Max fitness:15.651747983199279 && Average fitness:15.642186045255503\n",
            "-- Generation 14 --\n",
            " Max fitness:15.651747983199279 && Average fitness:15.645075263914773\n",
            "-- Generation 15 --\n",
            " Max fitness:15.653811710813041 && Average fitness:15.646623059625096\n",
            "-- Generation 16 --\n",
            " Max fitness:15.65587543842681 && Average fitness:15.644146586488574\n",
            "-- Generation 17 --\n",
            " Max fitness:15.656563347631401 && Average fitness:15.651128864915151\n",
            "-- Generation 18 --\n",
            " Max fitness:15.667569894904817 && Average fitness:15.650440955710565\n",
            "-- Generation 19 --\n",
            " Max fitness:15.667569894904817 && Average fitness:15.654293247256259\n",
            "-- Generation 20 --\n",
            " Max fitness:15.675136896155282 && Average fitness:15.660656407398704\n",
            "-- Generation 21 --\n",
            " Max fitness:15.675136896155282 && Average fitness:15.663923976120497\n",
            "-- Generation 22 --\n",
            " Max fitness:15.676512714564462 && Average fitness:15.663029694154531\n",
            "-- Generation 23 --\n",
            " Max fitness:15.681328078996579 && Average fitness:15.670699881785689\n",
            "-- Generation 24 --\n",
            " Max fitness:15.684079715814933 && Average fitness:15.675893596280332\n",
            "-- Generation 25 --\n",
            " Max fitness:15.690270898656227 && Average fitness:15.67785413751341\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 4 COMPLETED ----------------->\n",
            " Max fitness:15.691646717065403 && Average fitness:15.68098412439429\n",
            "5 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.589148245581745 && Average fitness:15.544537333664199\n",
            "-- Generation 2 --\n",
            " Max fitness:15.589148245581745 && Average fitness:15.571537769944282\n",
            "-- Generation 3 --\n",
            " Max fitness:15.60565806649187 && Average fitness:15.579655098558428\n",
            "-- Generation 4 --\n",
            " Max fitness:15.61460088615152 && Average fitness:15.592071859701244\n",
            "-- Generation 5 --\n",
            " Max fitness:15.619416250583637 && Average fitness:15.598503810764146\n",
            "-- Generation 6 --\n",
            " Max fitness:15.620104159788223 && Average fitness:15.601977752247317\n",
            "-- Generation 7 --\n",
            " Max fitness:15.634550253084576 && Average fitness:15.60988870810009\n",
            "-- Generation 8 --\n",
            " Max fitness:15.634550253084576 && Average fitness:15.616836591066425\n",
            "-- Generation 9 --\n",
            " Max fitness:15.634550253084576 && Average fitness:15.619828996106389\n",
            "-- Generation 10 --\n",
            " Max fitness:15.634550253084576 && Average fitness:15.628840606686495\n",
            "-- Generation 11 --\n",
            " Max fitness:15.64830843717634 && Average fitness:15.632796084612878\n",
            "-- Generation 12 --\n",
            " Max fitness:15.65174798319928 && Average fitness:15.63847133555073\n",
            "-- Generation 13 --\n",
            " Max fitness:15.65174798319928 && Average fitness:15.645591195818218\n",
            "-- Generation 14 --\n",
            " Max fitness:15.66344243967728 && Average fitness:15.648858764540012\n",
            "-- Generation 15 --\n",
            " Max fitness:15.667569894904808 && Average fitness:15.651094469454922\n",
            "-- Generation 16 --\n",
            " Max fitness:15.667569894904808 && Average fitness:15.652814242466391\n",
            "-- Generation 17 --\n",
            " Max fitness:15.66344243967728 && Average fitness:15.654809179159699\n",
            "-- Generation 18 --\n",
            " Max fitness:15.664818258086454 && Average fitness:15.655462692904056\n",
            "-- Generation 19 --\n",
            " Max fitness:15.673761077746102 && Average fitness:15.657320047756446\n",
            "-- Generation 20 --\n",
            " Max fitness:15.673761077746102 && Average fitness:15.662685739552234\n",
            "-- Generation 21 --\n",
            " Max fitness:15.67788853297363 && Average fitness:15.666400449257008\n",
            "-- Generation 22 --\n",
            " Max fitness:15.67788853297363 && Average fitness:15.668498572331\n",
            "-- Generation 23 --\n",
            " Max fitness:15.67788853297363 && Average fitness:15.667329126683203\n",
            "-- Generation 24 --\n",
            " Max fitness:15.690270898656218 && Average fitness:15.670665486325456\n",
            "-- Generation 25 --\n",
            " Max fitness:15.697149990702101 && Average fitness:15.674517777871149\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 5 COMPLETED ----------------->\n",
            " Max fitness:15.697149990702101 && Average fitness:15.672798004859677\n",
            "6 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.631798616266217 && Average fitness:15.54347107439709\n",
            "-- Generation 2 --\n",
            " Max fitness:15.640741435925863 && Average fitness:15.573979847620578\n",
            "-- Generation 3 --\n",
            " Max fitness:15.640741435925863 && Average fitness:15.616389450083442\n",
            "-- Generation 4 --\n",
            " Max fitness:15.640741435925866 && Average fitness:15.62877181576603\n",
            "-- Generation 5 --\n",
            " Max fitness:15.639365617516686 && Average fitness:15.627224020055706\n",
            "-- Generation 6 --\n",
            " Max fitness:15.654499620017626 && Average fitness:15.633724762039066\n",
            "-- Generation 7 --\n",
            " Max fitness:15.66275453047269 && Average fitness:15.640122317641735\n",
            "-- Generation 8 --\n",
            " Max fitness:15.672385259336924 && Average fitness:15.647689318892205\n",
            "-- Generation 9 --\n",
            " Max fitness:15.671009440927747 && Average fitness:15.652986219767536\n",
            "-- Generation 10 --\n",
            " Max fitness:15.675136896155276 && Average fitness:15.660656407398694\n",
            "-- Generation 11 --\n",
            " Max fitness:15.684079715814923 && Average fitness:15.665265399069437\n",
            "-- Generation 12 --\n",
            " Max fitness:15.687519261837862 && Average fitness:15.67379547320633\n",
            "-- Generation 13 --\n",
            " Max fitness:15.697837899906686 && Average fitness:15.681912801820465\n",
            "-- Generation 14 --\n",
            " Max fitness:15.717099357635155 && Average fitness:15.68975496675277\n",
            "-- Generation 15 --\n",
            " Max fitness:15.717099357635156 && Average fitness:15.69429516750306\n",
            "-- Generation 16 --\n",
            " Max fitness:15.727417995703979 && Average fitness:15.704373037350274\n",
            "-- Generation 17 --\n",
            " Max fitness:15.727417995703979 && Average fitness:15.713659811612217\n",
            "-- Generation 18 --\n",
            " Max fitness:15.727417995703979 && Average fitness:15.718096825981808\n",
            "-- Generation 19 --\n",
            " Max fitness:15.734297087749864 && Average fitness:15.716721007572636\n",
            "-- Generation 20 --\n",
            " Max fitness:15.736360815363625 && Average fitness:15.715792330146439\n",
            "-- Generation 21 --\n",
            " Max fitness:15.745991544227863 && Average fitness:15.728277882209715\n",
            "-- Generation 22 --\n",
            " Max fitness:15.745991544227863 && Average fitness:15.734950601494223\n",
            "-- Generation 23 --\n",
            " Max fitness:15.750118999455394 && Average fitness:15.734056319528259\n",
            "-- Generation 24 --\n",
            " Max fitness:15.758373909910452 && Average fitness:15.741657716238953\n",
            "-- Generation 25 --\n",
            " Max fitness:15.760437637524216 && Average fitness:15.743962212074331\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 6 COMPLETED ----------------->\n",
            " Max fitness:15.761125546728804 && Average fitness:15.748020876381398\n",
            "7 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.602218520468927 && Average fitness:15.531604640617942\n",
            "-- Generation 2 --\n",
            " Max fitness:15.602218520468927 && Average fitness:15.55530311271601\n",
            "-- Generation 3 --\n",
            " Max fitness:15.617352522969869 && Average fitness:15.581409267030134\n",
            "-- Generation 4 --\n",
            " Max fitness:15.617352522969869 && Average fitness:15.59444514645708\n",
            "-- Generation 5 --\n",
            " Max fitness:15.617352522969869 && Average fitness:15.6012554475825\n",
            "-- Generation 6 --\n",
            " Max fitness:15.620104159788221 && Average fitness:15.608375307849991\n",
            "-- Generation 7 --\n",
            " Max fitness:15.61941625058363 && Average fitness:15.611986831174075\n",
            "-- Generation 8 --\n",
            " Max fitness:15.619416250583633 && Average fitness:15.615082422594728\n",
            "-- Generation 9 --\n",
            " Max fitness:15.63592607149375 && Average fitness:15.617696477572162\n",
            "-- Generation 10 --\n",
            " Max fitness:15.63592607149375 && Average fitness:15.617352522969863\n",
            "-- Generation 11 --\n",
            " Max fitness:15.63592607149375 && Average fitness:15.62213349194175\n",
            "-- Generation 12 --\n",
            " Max fitness:15.64830843717634 && Average fitness:15.62488512876011\n",
            "-- Generation 13 --\n",
            " Max fitness:15.652435892403869 && Average fitness:15.635616512351685\n",
            "-- Generation 14 --\n",
            " Max fitness:15.652435892403869 && Average fitness:15.639193640215542\n",
            "-- Generation 15 --\n",
            " Max fitness:15.654499620017631 && Average fitness:15.644868891153394\n",
            "-- Generation 16 --\n",
            " Max fitness:15.657939166040572 && Average fitness:15.64658866416487\n",
            "-- Generation 17 --\n",
            " Max fitness:15.657251256835988 && Average fitness:15.647998878034272\n",
            "-- Generation 18 --\n",
            " Max fitness:15.670321531723163 && Average fitness:15.652676660625477\n",
            "-- Generation 19 --\n",
            " Max fitness:15.676512714564454 && Average fitness:15.659039820767916\n",
            "-- Generation 20 --\n",
            " Max fitness:15.682015988201163 && Average fitness:15.663029694154526\n",
            "-- Generation 21 --\n",
            " Max fitness:15.685455534224104 && Average fitness:15.670115158961782\n",
            "-- Generation 22 --\n",
            " Max fitness:15.695774172292923 && Average fitness:15.677613369291796\n",
            "-- Generation 23 --\n",
            " Max fitness:15.704716991952575 && Average fitness:15.684595647718368\n",
            "-- Generation 24 --\n",
            " Max fitness:15.71090817479387 && Average fitness:15.687897611900388\n",
            "-- Generation 25 --\n",
            " Max fitness:15.715035630021399 && Average fitness:15.693744840139393\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 7 COMPLETED ----------------->\n",
            " Max fitness:15.720538903658104 && Average fitness:15.696290104196368\n",
            "8 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.562319786602803 && Average fitness:15.541820092306072\n",
            "-- Generation 2 --\n",
            " Max fitness:15.588460336377155 && Average fitness:15.553617735164764\n",
            "-- Generation 3 --\n",
            " Max fitness:15.595339428423033 && Average fitness:15.56520900526208\n",
            "-- Generation 4 --\n",
            " Max fitness:15.607721794105634 && Average fitness:15.577969721007184\n",
            "-- Generation 5 --\n",
            " Max fitness:15.617352522969862 && Average fitness:15.585605513178113\n",
            "-- Generation 6 --\n",
            " Max fitness:15.625607433424921 && Average fitness:15.598606997144831\n",
            "-- Generation 7 --\n",
            " Max fitness:15.65243589240386 && Average fitness:15.6076873986454\n",
            "-- Generation 8 --\n",
            " Max fitness:15.652435892403862 && Average fitness:15.617765268492619\n",
            "-- Generation 9 --\n",
            " Max fitness:15.655187529222216 && Average fitness:15.631867407186679\n",
            "-- Generation 10 --\n",
            " Max fitness:15.659314984449743 && Average fitness:15.639056058374624\n",
            "-- Generation 11 --\n",
            " Max fitness:15.669633622518568 && Average fitness:15.644868891153397\n",
            "-- Generation 12 --\n",
            " Max fitness:15.668257804109391 && Average fitness:15.651954355960655\n",
            "-- Generation 13 --\n",
            " Max fitness:15.675136896155275 && Average fitness:15.659899707273642\n",
            "-- Generation 14 --\n",
            " Max fitness:15.684767625019514 && Average fitness:15.665574958211497\n",
            "-- Generation 15 --\n",
            " Max fitness:15.689582989451633 && Average fitness:15.666194076495623\n",
            "-- Generation 16 --\n",
            " Max fitness:15.689582989451633 && Average fitness:15.668120222268474\n",
            "-- Generation 17 --\n",
            " Max fitness:15.693710444679162 && Average fitness:15.672178886575546\n",
            "-- Generation 18 --\n",
            " Max fitness:15.689582989451633 && Average fitness:15.680915333473816\n",
            "-- Generation 19 --\n",
            " Max fitness:15.694398353883749 && Average fitness:15.683082247468272\n",
            "-- Generation 20 --\n",
            " Max fitness:15.711596083998456 && Average fitness:15.68738167999695\n",
            "-- Generation 21 --\n",
            " Max fitness:15.711596083998456 && Average fitness:15.693160117315491\n",
            "-- Generation 22 --\n",
            " Max fitness:15.711596083998456 && Average fitness:15.694535935724668\n",
            "-- Generation 23 --\n",
            " Max fitness:15.712283993203044 && Average fitness:15.695430217690634\n",
            "-- Generation 24 --\n",
            " Max fitness:15.716411448430573 && Average fitness:15.700933491327337\n",
            "-- Generation 25 --\n",
            " Max fitness:15.720538903658104 && Average fitness:15.704029082747988\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 8 COMPLETED ----------------->\n",
            " Max fitness:15.721914722067277 && Average fitness:15.71190564314052\n",
            "9 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.5918998824001 && Average fitness:15.544881288266495\n",
            "-- Generation 2 --\n",
            " Max fitness:15.604282248082685 && Average fitness:15.573670288478514\n",
            "-- Generation 3 --\n",
            " Max fitness:15.604282248082685 && Average fitness:15.586327817842937\n",
            "-- Generation 4 --\n",
            " Max fitness:15.617352522969862 && Average fitness:15.594926682900285\n",
            "-- Generation 5 --\n",
            " Max fitness:15.638677708312096 && Average fitness:15.600808306599514\n",
            "-- Generation 6 --\n",
            " Max fitness:15.652435892403858 && Average fitness:15.61460088615151\n",
            "-- Generation 7 --\n",
            " Max fitness:15.649684255585505 && Average fitness:15.627774347419372\n",
            "-- Generation 8 --\n",
            " Max fitness:15.649684255585505 && Average fitness:15.634997394067545\n",
            "-- Generation 9 --\n",
            " Max fitness:15.66000289365433 && Average fitness:15.639228035675767\n",
            "-- Generation 10 --\n",
            " Max fitness:15.66413034888186 && Average fitness:15.642082858874806\n",
            "-- Generation 11 --\n",
            " Max fitness:15.66413034888186 && Average fitness:15.643665050045362\n",
            "-- Generation 12 --\n",
            " Max fitness:15.671009440927742 && Average fitness:15.649030741841148\n",
            "-- Generation 13 --\n",
            " Max fitness:15.673073168541507 && Average fitness:15.65718246591552\n",
            "-- Generation 14 --\n",
            " Max fitness:15.673073168541507 && Average fitness:15.663958371580714\n",
            "-- Generation 15 --\n",
            " Max fitness:15.673073168541507 && Average fitness:15.665093421768287\n",
            "-- Generation 16 --\n",
            " Max fitness:15.673073168541507 && Average fitness:15.66877373601283\n",
            "-- Generation 17 --\n",
            " Max fitness:15.679264351382804 && Average fitness:15.670596695404992\n",
            "-- Generation 18 --\n",
            " Max fitness:15.68339180661033 && Average fitness:15.671353395530037\n",
            "-- Generation 19 --\n",
            " Max fitness:15.690958807860804 && Average fitness:15.67658150548491\n",
            "-- Generation 20 --\n",
            " Max fitness:15.704716991952568 && Average fitness:15.682841479246665\n",
            "-- Generation 21 --\n",
            " Max fitness:15.707468628770922 && Average fitness:15.68865431202543\n",
            "-- Generation 22 --\n",
            " Max fitness:15.708844447180097 && Average fitness:15.695808567753147\n",
            "-- Generation 23 --\n",
            " Max fitness:15.708844447180097 && Average fitness:15.70213733243536\n",
            "-- Generation 24 --\n",
            " Max fitness:15.721226812862685 && Average fitness:15.705060946554863\n",
            "-- Generation 25 --\n",
            " Max fitness:15.722602631271865 && Average fitness:15.707090278708396\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 9 COMPLETED ----------------->\n",
            " Max fitness:15.72810590490857 && Average fitness:15.713040693328088\n",
            "10 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.574702152285386 && Average fitness:15.539825155612766\n",
            "-- Generation 2 --\n",
            " Max fitness:15.574702152285386 && Average fitness:15.560152872608345\n",
            "-- Generation 3 --\n",
            " Max fitness:15.590524063990916 && Average fitness:15.569749206012352\n",
            "-- Generation 4 --\n",
            " Max fitness:15.609785521719381 && Average fitness:15.580033448620947\n",
            "-- Generation 5 --\n",
            " Max fitness:15.609785521719381 && Average fitness:15.587394077110039\n",
            "-- Generation 6 --\n",
            " Max fitness:15.617352522969854 && Average fitness:15.595098660201424\n",
            "-- Generation 7 --\n",
            " Max fitness:15.625607433424918 && Average fitness:15.601736984025703\n",
            "-- Generation 8 --\n",
            " Max fitness:15.646244709562568 && Average fitness:15.614738467992424\n",
            "-- Generation 9 --\n",
            " Max fitness:15.65312380160845 && Average fitness:15.623027773907712\n",
            "-- Generation 10 --\n",
            " Max fitness:15.65312380160845 && Average fitness:15.640328690403106\n",
            "-- Generation 11 --\n",
            " Max fitness:15.655187529222214 && Average fitness:15.64548800943752\n",
            "-- Generation 12 --\n",
            " Max fitness:15.655187529222214 && Average fitness:15.649649860125276\n",
            "-- Generation 13 --\n",
            " Max fitness:15.662754530472684 && Average fitness:15.651713587739042\n",
            "-- Generation 14 --\n",
            " Max fitness:15.6675698949048 && Average fitness:15.656253788489328\n",
            "-- Generation 15 --\n",
            " Max fitness:15.66413034888186 && Average fitness:15.653639733511886\n",
            "-- Generation 16 --\n",
            " Max fitness:15.670321531723154 && Average fitness:15.65649455671093\n",
            "-- Generation 17 --\n",
            " Max fitness:15.670321531723154 && Average fitness:15.662479366790851\n",
            "-- Generation 18 --\n",
            " Max fitness:15.676512714564451 && Average fitness:15.66591891281379\n",
            "-- Generation 19 --\n",
            " Max fitness:15.68820717104245 && Average fitness:15.665781330972871\n",
            "-- Generation 20 --\n",
            " Max fitness:15.688895080247038 && Average fitness:15.671078231848204\n",
            "-- Generation 21 --\n",
            " Max fitness:15.688895080247038 && Average fitness:15.675584037138254\n",
            "-- Generation 22 --\n",
            " Max fitness:15.688895080247038 && Average fitness:15.675721618979173\n",
            "-- Generation 23 --\n",
            " Max fitness:15.693710444679153 && Average fitness:15.679677096905555\n",
            "-- Generation 24 --\n",
            " Max fitness:15.69646208149751 && Average fitness:15.6810185198545\n",
            "-- Generation 25 --\n",
            " Max fitness:15.69646208149751 && Average fitness:15.678989187700969\n",
            "-- Generation 26 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<-------------------ITERATION 10 COMPLETED ----------------->\n",
            " Max fitness:15.69990162752045 && Average fitness:15.687794425519694\n",
            "<------------------------- APOTELESMATA ------------------------>\n",
            "Avg for generations: 14.461538461538462\n",
            "Best fitness of best individual: 15.761125546728804\n",
            "Avg fitness of best individual: 15.735135807818535\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best solution of best individual: [1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "population_size=20\n",
        "prob_cross = 0.6\n",
        "prob_mutation = 0.2\n",
        "genererations = 10\n",
        "\n",
        "averege_Fitness_all_gen=list()\n",
        "maxFitness_all_gen=list()\n",
        "Howmanygenerations =list()\n",
        "BestFitnessForAllGens =list()\n",
        "BestFitnessPerGens =list()\n",
        "BestFitness = list()\n",
        "genbest=list()\n",
        "best={}\n",
        "final_Bestfitness=list()\n",
        "X=[]\n",
        "\n",
        "def main(population_size,prob_cross,prob_mutation):\n",
        "  \n",
        "  \n",
        "  for i in range(10): # iterations\n",
        "      print(\"%d ITERATION \"%(i+1))\n",
        "\n",
        "       # dimiourgia plithismou\n",
        "      pop = toolbox.population(n=population_size)\n",
        "\n",
        "    #Evaluation fitness function \n",
        "      fitnesses = list(map(toolbox.evaluate, pop))\n",
        "      for ind, fit in zip(pop, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "   \n",
        "  \n",
        "    # CXPB pithanotita zeugaromatos\n",
        "    # MUTPB pithanotita metalakseis\n",
        "      CXPB, MUTPB = prob_cross, prob_mutation\n",
        "\n",
        "      #Statistics\n",
        "      stats = tools.Statistics(key=lambda ind:ind.fitness.values)\n",
        "      record = stats.compile(pop)\n",
        "      log = tools.Logbook()\n",
        "      log.record(gen=0, **record)\n",
        "\n",
        "\t# Extracting all the fitnesses of (epistrefi to fitness)\n",
        "      fits = [ind.fitness.values[0] for ind in pop]\n",
        "\t\n",
        "    # Variable keeping track of the number of generations\n",
        "    #metritis gia generation\n",
        "      generation=0\n",
        "      #Save to fitness pou exoume\n",
        "      previous_fit=max(fits)\n",
        "      #best fitness apo oles tis genies\n",
        "      bestfitness=0\n",
        "  #creteria \n",
        "      g = 1\n",
        "      critiria = False \n",
        "      max_g=50\n",
        "      fitness_unchanged = 0\n",
        "\n",
        "  # Begin the evolution\n",
        "      while critiria==False :\n",
        "        generation +=1\n",
        "\n",
        "    # A new generation\n",
        "        print(\"-- Generation %i --\" % generation) \n",
        "\n",
        "    # Select the next generation individuals\n",
        "        offspring = toolbox.select(pop, len(pop))\n",
        "    # Clone the selected individuals\n",
        "        offspring = list(map(toolbox.clone, offspring)) \n",
        "\n",
        "    # Apply crossover and mutation on the offspring\n",
        "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "            if random.random() < CXPB:\n",
        "                toolbox.mate(child1, child2)\n",
        "                del child1.fitness.values\n",
        "                del child2.fitness.values\n",
        "\n",
        "        for mutant in offspring:\n",
        "            if random.random() < MUTPB:\n",
        "                toolbox.mutate(mutant)\n",
        "                del mutant.fitness.values\n",
        "\n",
        "\n",
        "    # Evaluate the individuals with an invalid fitness\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "    # Replace the old population by the offspring\n",
        "        pop[:] = offspring\n",
        "\n",
        "    \n",
        "    # Gather all the fitnesses in one list and print the stats\n",
        "        fitness = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "        record = stats.compile(pop)\n",
        "        log.record(gen=g, **record)  \n",
        "        best = log.select(\"max\")\n",
        "\n",
        "    #CRETERIA FOR WHILE LOOP(OSO TO TERM=FALSE trexei h while)\n",
        "        # reached max number of generations\n",
        "        if g >= max_g:\n",
        "            critiria = True\n",
        "            print(\"<-------------------ITERATION %d COMPLETED ----------------->\" %(i+1))\n",
        "        # best individual of gen is <1% better than best individual of previous gen\n",
        "        elif (g > 25) and max(fits) < (1.001*previous_fit):\n",
        "            critiria = True\n",
        "            print(\"<-------------------ITERATION %d COMPLETED ----------------->\" %(i+1))\n",
        "        # best individual of gen is same as best individual of previous gen\n",
        "        elif (g > 25) and previous_fit == max(fits):\n",
        "            fitness_unchanged += 1\n",
        "            #ean g>25 kai exw 5 fores stasimo fitness tote critiria=True\n",
        "            if fitness_unchanged >= 5:\n",
        "                critiria = True\n",
        "                print(\"<-------------------ITERATION %d COMPLETED ----------------->\" %(i+1))\n",
        "            else:\n",
        "                g += 1\n",
        "        # else continue\n",
        "        else:\n",
        "            fitness_unchanged = 0\n",
        "            g += 1\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "#------------------------------------EKTELESI GIA KATHE GENIA-----------------------------------------------------------------------------\n",
        "        #GIA KATHE GENERATION:\n",
        "        maxFitness_per_gen=(max(fitness))\n",
        "        average_fitness_per_gen = ((sum(fitness)/len(pop)))\n",
        "        print(\" Max fitness:%s && Average fitness:%s\" %((maxFitness_per_gen),(average_fitness_per_gen)))\n",
        "    \n",
        "\n",
        "#--------------------------------------TO MEGALITERO KATHE GENIAS KAI TO ANTISTOIXO AVG ----------------------------------------------------------------------\n",
        "        maxFitness_all_gen.append(maxFitness_per_gen)\n",
        "        averege_Fitness_all_gen.append(average_fitness_per_gen)\n",
        "\n",
        "        #TWRA THELOUME APO OLES TIS GENIES NA KRATISOUME MONO ENA, TO MEGALITERO \n",
        "        final_Bestfitness.append(max(maxFitness_all_gen))\n",
        "\n",
        "#----------------------------------------------SUNOLIKES GENIES EKTELESIS---------------------------------------------------------------------------------\n",
        "        Howmanygenerations.append(g)\n",
        "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "        #PREPEI NA VROUME TO BEST FITNESS \n",
        "        best_fitness =max(fitness)\n",
        "        if best_fitness > bestfitness:\n",
        "            bestfitness = best_fitness\n",
        "            Bestindex =pop[fitness.index(best_fitness)]\n",
        "        BestFitnessPerGens.append(best_fitness)\n",
        "\n",
        "         \n",
        "        #Vale stin lista mono to megalutero stoixio pou vrikes\n",
        "        BestFitnessForAllGens.append(max(BestFitnessPerGens))\n",
        "        X.append(mean(BestFitnessPerGens))\n",
        "#################################################################################\n",
        "      \n",
        "\n",
        "################################################################################ \n",
        "\n",
        "  best_ind =tools.selBest(pop,1)[0]\n",
        "  print(\"<------------------------- APOTELESMATA ------------------------>\")\n",
        "  print(\"Avg for generations:\",mean(Howmanygenerations))\n",
        "  print(\"Best fitness of best individual:\",np.amax(max(BestFitnessForAllGens)))\n",
        "  print(\"Avg fitness of best individual:\",np.mean(BestFitnessForAllGens))\n",
        "\n",
        "\n",
        "  plt.figure(0)\n",
        "  plt.subplot(2, 2, 1)\n",
        "  plt.plot(BestFitnessForAllGens,color='red')\n",
        "  plt.title(\"MAX\")\n",
        "  plt.ylabel(\"Max fitness\")\n",
        "  plt.xlabel(\"Generation\")\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(2, 2, 2)\n",
        "  plt.plot(X,color=\"green\")\n",
        "  plt.title(\"AVG\")\n",
        "  plt.ylabel(\"Avg fitness\")\n",
        "  plt.xlabel(\"Generation\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Best solution of best individual:\",(best_ind))\n",
        "\n",
        "  return best_ind\n",
        " \n",
        "keep = main(population_size,prob_cross,prob_mutation)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dYaYp4GeFPUo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "tf_idf_Xtrain=tf_idf_Xtrain[:8251]\n",
        "labels_fnames = [\n",
        "            'train-label.dat',\n",
        "            ]\n",
        "y = pd.read_csv(labels_fnames[0] , delimiter = ' ', header = None)\n",
        "\n",
        "\n",
        "clean_doc = []\n",
        "wordfreq = {}\n",
        "for doc in file:\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    for token in tokens:\n",
        "        if token not in wordfreq.keys():\n",
        "            wordfreq[token] = 1\n",
        "        else:\n",
        "            wordfreq[token] += 1\n",
        "            \n",
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist()\n",
        "\n",
        "sentence_vectors = []\n",
        "for doc in file:\n",
        "    doc_tokens = nltk.word_tokenize(doc)\n",
        "    vec = []\n",
        "    for token in wordfreq:\n",
        "        if token in doc_tokens:\n",
        "            count = 0\n",
        "            for tok in doc_tokens:\n",
        "                if tok == token:\n",
        "                    count += 1\n",
        "            vec.append(count)\n",
        "        else:\n",
        "            vec.append(0)\n",
        "    sentence_vectors.append(vec)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkLKPx6YFPUp",
        "outputId": "d34568aa-f9de-4977-bec5-fee3f7bc1375"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8251, 8522)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_train =np.array(sentence_vectors)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj3oO9LyFPUq",
        "outputId": "9c103c61-6806-4f67-c264-ab8ecf77061e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5775, 8522) (2476, 8522) (5775, 20) (2476, 20)\n"
          ]
        }
      ],
      "source": [
        "X_train.shape\n",
        "for i in range(len(keep)):\n",
        "    if keep[i] == 0:\n",
        "        X_train[:,i] = 0\n",
        "        \n",
        "       \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, y, test_size=0.3, random_state=0)  \n",
        "\n",
        "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkgvFzRHFPUr",
        "outputId": "29985254-b8ea-4afd-e60f-2f39f03b1a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5775, 7565) (2476, 7565) (5775, 20) (2476, 20)\n"
          ]
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_minmax = scaler.fit_transform(X_train)\n",
        "X_test_minmax=scaler.fit_transform(X_test)\n",
        "X_train_minmax=X_train[:,:-957]\n",
        "X_test_minmax=X_test[:,:-957]\n",
        "print(X_train_minmax.shape,X_test_minmax.shape,Y_train.shape,Y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "n0RrA-HGFPUs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "model = tf.keras.models.load_model(\"ce.h5\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T_qGEDqcFPUt",
        "outputId": "94d5e94f-a481-4e53-e6b3-876633004c2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1853 - accuracy: 0.3922\n",
            "Epoch 2/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1828 - accuracy: 0.3919\n",
            "Epoch 3/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1811 - accuracy: 0.3995\n",
            "Epoch 4/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.3929\n",
            "Epoch 5/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.3938\n",
            "Epoch 6/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.3969\n",
            "Epoch 7/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1749 - accuracy: 0.3988\n",
            "Epoch 8/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.3960\n",
            "Epoch 9/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1724 - accuracy: 0.4010\n",
            "Epoch 10/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1708 - accuracy: 0.4029\n",
            "Epoch 11/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1685 - accuracy: 0.4010\n",
            "Epoch 12/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1676 - accuracy: 0.4055\n",
            "Epoch 13/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1652 - accuracy: 0.4005\n",
            "Epoch 14/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1640 - accuracy: 0.4088\n",
            "Epoch 15/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1632 - accuracy: 0.4057\n",
            "Epoch 16/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1622 - accuracy: 0.4031\n",
            "Epoch 17/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1597 - accuracy: 0.4033\n",
            "Epoch 18/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1584 - accuracy: 0.4087\n",
            "Epoch 19/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1577 - accuracy: 0.4061\n",
            "Epoch 20/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1553 - accuracy: 0.4107\n",
            "Epoch 21/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1537 - accuracy: 0.4137\n",
            "Epoch 22/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1531 - accuracy: 0.4083\n",
            "Epoch 23/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1507 - accuracy: 0.4102\n",
            "Epoch 24/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1485 - accuracy: 0.4144\n",
            "Epoch 25/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1470 - accuracy: 0.4147\n",
            "Epoch 26/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1456 - accuracy: 0.4144\n",
            "Epoch 27/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1451 - accuracy: 0.4154\n",
            "Epoch 28/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1431 - accuracy: 0.4149\n",
            "Epoch 29/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1414 - accuracy: 0.4159\n",
            "Epoch 30/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1417 - accuracy: 0.4140\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.2322\n",
            "Accuracy for  retrained model is 0.23222939670085907\n",
            "Lose for retrained model is  0.3881796896457672\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train_minmax,Y_train, epochs=30 , verbose=1)\n",
        "losse1,accuracy1=model.evaluate(X_test_minmax,Y_test)\n",
        "print(\"Accuracy for  retrained model is\", accuracy1)\n",
        "print(\"Lose for retrained model is \",losse1)\n",
        "\n",
        "#loss2, accuracy2 = model.evaluate(X_test_minmax, Y_test, verbose=0)\n",
        "#print(\"Accuracy for  retrained model is\", accuracy2)\n",
        "#print(\"Lose for retrained model is \",loss2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MyqE1BrIFPUt"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "moNYpuITFPUu"
      },
      "outputs": [],
      "source": [
        "labels_fnames = [\n",
        "            'test-label.dat'\n",
        "            ]\n",
        "Y_test= pd.read_csv(labels_fnames[0] ,nrows=2476,delimiter = ' ', header = None)\n",
        "\n",
        "#TEST-DATA\n",
        "path = 'test-data.dat'\n",
        "\n",
        "clean_files = []\n",
        "df = pd.DataFrame()\n",
        "\n",
        "file = open(path).readlines()\n",
        "len(file)\n",
        "\n",
        "clean_docc = []\n",
        "wordfreqq = {}\n",
        "for doc in file:\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    for token in tokens:\n",
        "        if token not in wordfreqq.keys():\n",
        "            wordfreqq[token] = 1\n",
        "        else:\n",
        "            wordfreqq[token] += 1\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "fdist = FreqDist()\n",
        "sentence_vectorss = []\n",
        "for doc in file:\n",
        "    doc_tokens = nltk.word_tokenize(doc)\n",
        "    vecc = []\n",
        "    for token in wordfreqq:\n",
        "        if token in doc_tokens:\n",
        "            count = 0\n",
        "            for tok in doc_tokens:\n",
        "                if tok == token:\n",
        "                    count += 1\n",
        "            vecc.append(count)\n",
        "        else:\n",
        "            vecc.append(0)\n",
        "    sentence_vectorss.append(vecc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5Co3lBkrFPUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9cdf8fd-5804-497e-9053-fb2ee0435cc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2476, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "X_test =np.array(sentence_vectorss)\n",
        "X_test_new=scaler.fit_transform(X_test)\n",
        "X_test_new=X_test[:-1507,:-638]\n",
        "Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Firstly, we dont retrain the ANN.\n",
        "loss, accuracy = model.evaluate(X_test_new, Y_test, verbose=0)\n",
        "print(\"Accuracy for non retrained model is\", accuracy)\n",
        "print(\"loss for non retrained model is\", loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1rwmImvihiO",
        "outputId": "735de6e8-8d18-4140-97e9-9ba0c1c4b41c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for non retrained model is 0.10945072770118713\n",
            "loss for non retrained model is 0.700946569442749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Aq2E0wI8iw4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "my_final_ga.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}