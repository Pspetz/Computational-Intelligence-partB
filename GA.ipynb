{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqXnrz8JFPUU",
        "outputId": "5c24aab1-4540-4dae-8598-885e4a22091a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/spetz/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "#!pip install deap\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np \n",
        "import math\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from deap import algorithms, base, creator, tools\n",
        "from nltk import word_tokenize\n",
        "import re, string\n",
        "import random\n",
        "import statistics \n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "orabcQu0FPUZ"
      },
      "outputs": [],
      "source": [
        "dict_freq = {}  # frequency map for words in list\n",
        "dict_paired_freq = {}\n",
        "\n",
        "path = 'train-data.dat'\n",
        "clean_files = []\n",
        "df = pd.DataFrame()\n",
        "\n",
        "file = open(path).readlines()\n",
        "len(file)\n",
        "\n",
        "#clear data\n",
        "clear_file=[]\n",
        "for i in range(len(file)):\n",
        "    x=re.sub('<.*?>','',file[i])\n",
        "    clear_file.append(x)\n",
        "\n",
        "clear_file=clear_file[:]\n",
        "\n",
        "#perasma tou clear keimenou sto words string\n",
        "words = ''\n",
        "for line in clear_file:\n",
        "    words += line\n",
        "\n",
        "\n",
        "tokenized_words = word_tokenize(words) # list of all words in new dictionary\n",
        "WORD_LIST = list(set(tokenized_words)) # create a set out of words so there are no repeats in word list and make list again\n",
        "dictionary_size = len(WORD_LIST) #6853\n",
        "\n",
        "\n",
        "#Dhmiourgia dictionary lekseis kai suxnotitas emfanisi tis lekseis se olo to keimeno\n",
        "for word in tokenized_words: #gia kathe word sto lista leksewn olou tou keimenou\n",
        "    if word not in dict_freq: \n",
        "        dict_freq[word] = 1\n",
        "    else:\n",
        "        dict_freq[word] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JHVW15MFPUb",
        "outputId": "15f8dd2b-e280-41d5-f60c-2230c7ab9a07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8520"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TF = (Frequency of the word in the sentence) / (Total number of words in the sentence)\n",
        "def computeTF(wordDict,bow):\n",
        "    tfDict={}\n",
        "    bowCount=len(bow)\n",
        "    for word,count in wordDict.items():\n",
        "        tfDict[word] = count/float(bowCount)\n",
        "    return tfDict\n",
        "\n",
        "tf=computeTF(dict_freq,tokenized_words)\n",
        "\n",
        "#IDF: log((Total number of sentences (documents))/(Number of sentences (documents) containing the word))\n",
        "def computeIDF(docList):\n",
        "    idfDict = {}\n",
        "    N = len(docList)\n",
        "    \n",
        "    idfDict = dict.fromkeys(dict_freq,0)\n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
        "        \n",
        "    return idfDict\n",
        "\n",
        "idf=computeIDF(dict_freq)\n",
        "len(idf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R1IAnJbJFPUc"
      },
      "outputs": [],
      "source": [
        "#FINAL TF-IDF\n",
        "def computeDFIDF(tfbow,idfs):\n",
        "    tfidf={}\n",
        "    for word,val in tfbow.items():\n",
        "        tfidf[word] = val*idfs[word]\n",
        "\n",
        "    return tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NoLp9o8vFPUd"
      },
      "outputs": [],
      "source": [
        "#final TF-IDF\n",
        "Tf_idf=computeDFIDF(tf,idf)\n",
        "#Apothikeusi mono ton timwn\n",
        "new_list = list(Tf_idf.values())\n",
        "len(new_list)\n",
        "tf_idf_Xtrain = np.asarray(new_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "t7W7Pb_-FPUd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/spetz/.local/lib/python3.10/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/home/spetz/.local/lib/python3.10/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        }
      ],
      "source": [
        "#Create a FitnessMax class \n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "#Create an Individual class \n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "def getFitness(individual):\n",
        "    counter = 0\n",
        "    fitness = 0\n",
        "\n",
        "    #gia kathe thesi sto indi\n",
        "    for word_index in individual:\n",
        "        #vale sto string thn antistoixi leksi\n",
        "        if new_list[word_index] < 1:\n",
        "            fitness += new_list[word_index]\n",
        "    #penalty for >1000 times of 1\n",
        "    counter = 0 \n",
        "    for word_index in individual:  \n",
        "        if word_index==1:\n",
        "            counter+=1\n",
        "    if counter<1000:\n",
        "        fitness -= 10\n",
        "    else:\n",
        "        pass\n",
        "  \n",
        "    return fitness,\n",
        "\n",
        "        \n",
        "#The toolbox is a container for functions with their arguments\n",
        "toolbox = base.Toolbox()\n",
        "# Attribute generator \n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "# Structure initializers\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, len(new_list))\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual) \n",
        "# Register the genetic operators\t\n",
        "toolbox.register(\"evaluate\", getFitness)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jvmuO4gpFPUf",
        "outputId": "8745fb13-b839-48bd-d62d-09ad4903a682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.600154792855152 && Average fitness:15.53851812812405\n",
            "-- Generation 2 --\n",
            " Max fitness:15.596027337627623 && Average fitness:15.565380982563218\n",
            "-- Generation 3 --\n",
            " Max fitness:15.596027337627623 && Average fitness:15.57762576640489\n",
            "-- Generation 4 --\n",
            " Max fitness:15.61666461376527 && Average fitness:15.58928582742266\n",
            "-- Generation 5 --\n",
            " Max fitness:15.61666461376527 && Average fitness:15.596405687690151\n",
            "-- Generation 6 --\n",
            " Max fitness:15.624231615015741 && Average fitness:15.606036416554383\n",
            "-- Generation 7 --\n",
            " Max fitness:15.63592607149374 && Average fitness:15.612090017554758\n",
            "-- Generation 8 --\n",
            " Max fitness:15.642805163539624 && Average fitness:15.622890192066794\n",
            "-- Generation 9 --\n",
            " Max fitness:15.647620527971744 && Average fitness:15.631007520680939\n",
            "-- Generation 10 --\n",
            " Max fitness:15.647620527971744 && Average fitness:15.638987267454155\n",
            "-- Generation 11 --\n",
            " Max fitness:15.650372164790088 && Average fitness:15.641463740590675\n",
            "-- Generation 12 --\n",
            " Max fitness:15.66619407649562 && Average fitness:15.642323627096413\n",
            "-- Generation 13 --\n",
            " Max fitness:15.666881985700208 && Average fitness:15.648377228096788\n",
            "-- Generation 14 --\n",
            " Max fitness:15.6675698949048 && Average fitness:15.64964986012528\n",
            "-- Generation 15 --\n",
            " Max fitness:15.6675698949048 && Average fitness:15.657216861375744\n",
            "-- Generation 16 --\n",
            " Max fitness:15.66963362251856 && Average fitness:15.660759593779371\n",
            "-- Generation 17 --\n",
            " Max fitness:15.67100944092774 && Average fitness:15.662582553171529\n",
            "-- Generation 18 --\n",
            " Max fitness:15.682015988201154 && Average fitness:15.666400449257\n",
            "-- Generation 19 --\n",
            " Max fitness:15.682703897405743 && Average fitness:15.668876922393522\n",
            "-- Generation 20 --\n",
            " Max fitness:15.687519261837856 && Average fitness:15.670906254547052\n",
            "-- Generation 21 --\n",
            " Max fitness:15.687519261837856 && Average fitness:15.674448986950683\n",
            "-- Generation 22 --\n",
            " Max fitness:15.695774172292914 && Average fitness:15.67964270144532\n",
            "-- Generation 23 --\n",
            " Max fitness:15.699901627520443 && Average fitness:15.68390773851377\n",
            "-- Generation 24 --\n",
            " Max fitness:15.711596083998442 && Average fitness:15.689411012150472\n",
            "-- Generation 25 --\n",
            " Max fitness:15.715723539225971 && Average fitness:15.6979754817476\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 1 COMPLETED ----------------->\n",
            " Max fitness:15.715723539225971 && Average fitness:15.70127744592962\n",
            "2 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.57195051546705 && Average fitness:15.545913152073378\n",
            "-- Generation 2 --\n",
            " Max fitness:15.596027337627637 && Average fitness:15.559740127085604\n",
            "-- Generation 3 --\n",
            " Max fitness:15.596027337627637 && Average fitness:15.570299533376033\n",
            "-- Generation 4 --\n",
            " Max fitness:15.602906429673519 && Average fitness:15.58529595403606\n",
            "-- Generation 5 --\n",
            " Max fitness:15.627671161038693 && Average fitness:15.597540737877733\n",
            "-- Generation 6 --\n",
            " Max fitness:15.627671161038691 && Average fitness:15.60734344404311\n",
            "-- Generation 7 --\n",
            " Max fitness:15.627671161038691 && Average fitness:15.614738467992435\n",
            "-- Generation 8 --\n",
            " Max fitness:15.635238162289163 && Average fitness:15.621479978197396\n",
            "-- Generation 9 --\n",
            " Max fitness:15.655187529222225 && Average fitness:15.628152697481903\n",
            "-- Generation 10 --\n",
            " Max fitness:15.657939166040578 && Average fitness:15.629287747669474\n",
            "-- Generation 11 --\n",
            " Max fitness:15.66069080285893 && Average fitness:15.635513325970994\n",
            "-- Generation 12 --\n",
            " Max fitness:15.665506167291042 && Average fitness:15.64442175017042\n",
            "-- Generation 13 --\n",
            " Max fitness:15.67582480535987 && Average fitness:15.651025678534463\n",
            "-- Generation 14 --\n",
            " Max fitness:15.67582480535987 && Average fitness:15.661997830347648\n",
            "-- Generation 15 --\n",
            " Max fitness:15.684079715814928 && Average fitness:15.666916381160451\n",
            "-- Generation 16 --\n",
            " Max fitness:15.692334626269986 && Average fitness:15.67441459149046\n",
            "-- Generation 17 --\n",
            " Max fitness:15.697837899906695 && Average fitness:15.682153570042084\n",
            "-- Generation 18 --\n",
            " Max fitness:15.704716991952573 && Average fitness:15.688103984661769\n",
            "-- Generation 19 --\n",
            " Max fitness:15.712283993203052 && Average fitness:15.692403417190448\n",
            "-- Generation 20 --\n",
            " Max fitness:15.71641144843057 && Average fitness:15.701621400531929\n",
            "-- Generation 21 --\n",
            " Max fitness:15.71641144843057 && Average fitness:15.706299183123122\n",
            "-- Generation 22 --\n",
            " Max fitness:15.730169632522337 && Average fitness:15.707331046930008\n",
            "-- Generation 23 --\n",
            " Max fitness:15.730169632522337 && Average fitness:15.70898202902102\n",
            "-- Generation 24 --\n",
            " Max fitness:15.730169632522337 && Average fitness:15.718991107947778\n",
            "-- Generation 25 --\n",
            " Max fitness:15.744615725818688 && Average fitness:15.721467581084298\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 2 COMPLETED ----------------->\n",
            " Max fitness:15.742551998204924 && Average fitness:15.727761950306277\n",
            "3 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.620792068992806 && Average fitness:15.54856160251104\n",
            "-- Generation 2 --\n",
            " Max fitness:15.620792068992806 && Average fitness:15.565140214341614\n",
            "-- Generation 3 --\n",
            " Max fitness:15.620792068992806 && Average fitness:15.585777490479263\n",
            "-- Generation 4 --\n",
            " Max fitness:15.624919524220342 && Average fitness:15.605382902810026\n",
            "-- Generation 5 --\n",
            " Max fitness:15.641429345130458 && Average fitness:15.613637813265086\n",
            "-- Generation 6 --\n",
            " Max fitness:15.641429345130458 && Average fitness:15.620379323470056\n",
            "-- Generation 7 --\n",
            " Max fitness:15.641429345130458 && Average fitness:15.624300405936207\n",
            "-- Generation 8 --\n",
            " Max fitness:15.650372164790108 && Average fitness:15.625951388027218\n",
            "-- Generation 9 --\n",
            " Max fitness:15.650372164790108 && Average fitness:15.630388402396814\n",
            "-- Generation 10 --\n",
            " Max fitness:15.651747983199286 && Average fitness:15.634962998607325\n",
            "-- Generation 11 --\n",
            " Max fitness:15.668945713313992 && Average fitness:15.638952871993942\n",
            "-- Generation 12 --\n",
            " Max fitness:15.668945713313992 && Average fitness:15.647586132511526\n",
            "-- Generation 13 --\n",
            " Max fitness:15.67720062376905 && Average fitness:15.6563225794098\n",
            "-- Generation 14 --\n",
            " Max fitness:15.67720062376905 && Average fitness:15.662788925932926\n",
            "-- Generation 15 --\n",
            " Max fitness:15.67720062376905 && Average fitness:15.668773736012843\n",
            "-- Generation 16 --\n",
            " Max fitness:15.67720062376905 && Average fitness:15.673485914064276\n",
            "-- Generation 17 --\n",
            " Max fitness:15.67720062376905 && Average fitness:15.674208218729092\n",
            "-- Generation 18 --\n",
            " Max fitness:15.678576442178226 && Average fitness:15.673692286825652\n",
            "-- Generation 19 --\n",
            " Max fitness:15.678576442178226 && Average fitness:15.674345800570006\n",
            "-- Generation 20 --\n",
            " Max fitness:15.678576442178226 && Average fitness:15.675308873456434\n",
            "-- Generation 21 --\n",
            " Max fitness:15.678576442178226 && Average fitness:15.675033709774596\n",
            "-- Generation 22 --\n",
            " Max fitness:15.678576442178226 && Average fitness:15.676684691865606\n",
            "-- Generation 23 --\n",
            " Max fitness:15.678576442178226 && Average fitness:15.674139427808626\n",
            "-- Generation 24 --\n",
            " Max fitness:15.678576442178226 && Average fitness:15.67255723663807\n",
            "-- Generation 25 --\n",
            " Max fitness:15.678576442178226 && Average fitness:15.676443923643996\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 3 COMPLETED ----------------->\n",
            " Max fitness:15.678576442178226 && Average fitness:15.667329126683205\n",
            "4 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.595339428423037 && Average fitness:15.562766927585788\n",
            "-- Generation 2 --\n",
            " Max fitness:15.609785521719388 && Average fitness:15.58096212604715\n",
            "-- Generation 3 --\n",
            " Max fitness:15.609785521719388 && Average fitness:15.589904945706795\n",
            "-- Generation 4 --\n",
            " Max fitness:15.622855796606569 && Average fitness:15.601874565866629\n",
            "-- Generation 5 --\n",
            " Max fitness:15.622855796606569 && Average fitness:15.604213457162222\n",
            "-- Generation 6 --\n",
            " Max fitness:15.63798979910751 && Average fitness:15.611505294730861\n",
            "-- Generation 7 --\n",
            " Max fitness:15.655187529222218 && Average fitness:15.61649263646413\n",
            "-- Generation 8 --\n",
            " Max fitness:15.642117254335043 && Average fitness:15.623784474032766\n",
            "-- Generation 9 --\n",
            " Max fitness:15.65312380160845 && Average fitness:15.628737420305796\n",
            "-- Generation 10 --\n",
            " Max fitness:15.652435892403865 && Average fitness:15.634275089402731\n",
            "-- Generation 11 --\n",
            " Max fitness:15.65793916604057 && Average fitness:15.645144054835232\n",
            "-- Generation 12 --\n",
            " Max fitness:15.661378712063511 && Average fitness:15.650750514852621\n",
            "-- Generation 13 --\n",
            " Max fitness:15.671009440927747 && Average fitness:15.653089406148222\n",
            "-- Generation 14 --\n",
            " Max fitness:15.673073168541512 && Average fitness:15.658386307023548\n",
            "-- Generation 15 --\n",
            " Max fitness:15.673073168541512 && Average fitness:15.664508698944388\n",
            "-- Generation 16 --\n",
            " Max fitness:15.674448986950686 && Average fitness:15.667707476745727\n",
            "-- Generation 17 --\n",
            " Max fitness:15.706780719566327 && Average fitness:15.668154617728707\n",
            "-- Generation 18 --\n",
            " Max fitness:15.703341173543388 && Average fitness:15.676753482786058\n",
            "-- Generation 19 --\n",
            " Max fitness:15.705404901157156 && Average fitness:15.682669501945515\n",
            "-- Generation 20 --\n",
            " Max fitness:15.713659811612208 && Average fitness:15.696978013400946\n",
            "-- Generation 21 --\n",
            " Max fitness:15.717787266839744 && Average fitness:15.70258447341834\n",
            "-- Generation 22 --\n",
            " Max fitness:15.72260263127186 && Average fitness:15.708982029021012\n",
            "-- Generation 23 --\n",
            " Max fitness:15.723290540476448 && Average fitness:15.709532356384681\n",
            "-- Generation 24 --\n",
            " Max fitness:15.72329054047645 && Average fitness:15.709738729146059\n",
            "-- Generation 25 --\n",
            " Max fitness:15.730857541726918 && Average fitness:15.720401321817178\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 4 COMPLETED ----------------->\n",
            " Max fitness:15.732921269340682 && Average fitness:15.718887921567084\n",
            "5 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.614600886151528 && Average fitness:15.539653178311625\n",
            "-- Generation 2 --\n",
            " Max fitness:15.622855796606585 && Average fitness:15.568648551285019\n",
            "-- Generation 3 --\n",
            " Max fitness:15.622855796606585 && Average fitness:15.597162387815207\n",
            "-- Generation 4 --\n",
            " Max fitness:15.622855796606585 && Average fitness:15.609854312639865\n",
            "-- Generation 5 --\n",
            " Max fitness:15.632486525470817 && Average fitness:15.61841878223699\n",
            "-- Generation 6 --\n",
            " Max fitness:15.635926071493756 && Average fitness:15.61996657794731\n",
            "-- Generation 7 --\n",
            " Max fitness:15.650372164790113 && Average fitness:15.6276711610387\n",
            "-- Generation 8 --\n",
            " Max fitness:15.657251256835997 && Average fitness:15.635616512351698\n",
            "-- Generation 9 --\n",
            " Max fitness:15.657251256835997 && Average fitness:15.643974609187444\n",
            "-- Generation 10 --\n",
            " Max fitness:15.659314984449761 && Average fitness:15.650819305773094\n",
            "-- Generation 11 --\n",
            " Max fitness:15.659314984449761 && Average fitness:15.652470287864109\n",
            "-- Generation 12 --\n",
            " Max fitness:15.67307316854153 && Average fitness:15.65463720185856\n",
            "-- Generation 13 --\n",
            " Max fitness:15.675824805359877 && Average fitness:15.656769720392782\n",
            "-- Generation 14 --\n",
            " Max fitness:15.682015988201174 && Average fitness:15.661000362000996\n",
            "-- Generation 15 --\n",
            " Max fitness:15.683391806610347 && Average fitness:15.668808131473076\n",
            "-- Generation 16 --\n",
            " Max fitness:15.690270898656234 && Average fitness:15.67582480535988\n",
            "-- Generation 17 --\n",
            " Max fitness:15.694398353883763 && Average fitness:15.676443923644012\n",
            "-- Generation 18 --\n",
            " Max fitness:15.69990162752047 && Average fitness:15.68115610169544\n",
            "-- Generation 19 --\n",
            " Max fitness:15.70746862877094 && Average fitness:15.68469883409907\n",
            "-- Generation 20 --\n",
            " Max fitness:15.708156537975526 && Average fitness:15.697562736224867\n",
            "-- Generation 21 --\n",
            " Max fitness:15.708156537975526 && Average fitness:15.700039209361387\n",
            "-- Generation 22 --\n",
            " Max fitness:15.710220265589292 && Average fitness:15.700004813901156\n",
            "-- Generation 23 --\n",
            " Max fitness:15.714347720816821 && Average fitness:15.703341173543413\n",
            "-- Generation 24 --\n",
            " Max fitness:15.719850994453527 && Average fitness:15.707881374293692\n",
            "-- Generation 25 --\n",
            " Max fitness:15.719850994453527 && Average fitness:15.70966993822562\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 5 COMPLETED ----------------->\n",
            " Max fitness:15.728105904908583 && Average fitness:15.713900579833833\n",
            "6 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.604970157287285 && Average fitness:15.554340039829583\n",
            "-- Generation 2 --\n",
            " Max fitness:15.604970157287285 && Average fitness:15.567169546495155\n",
            "-- Generation 3 --\n",
            " Max fitness:15.607721794105638 && Average fitness:15.58168443071197\n",
            "-- Generation 4 --\n",
            " Max fitness:15.611161340128579 && Average fitness:15.592553396144467\n",
            "-- Generation 5 --\n",
            " Max fitness:15.611161340128579 && Average fitness:15.59819425162209\n",
            "-- Generation 6 --\n",
            " Max fitness:15.61804043217446 && Average fitness:15.603215988815583\n",
            "-- Generation 7 --\n",
            " Max fitness:15.61804043217446 && Average fitness:15.609441567117107\n",
            "-- Generation 8 --\n",
            " Max fitness:15.624919524220344 && Average fitness:15.61098936282743\n",
            "-- Generation 9 --\n",
            " Max fitness:15.628359070243288 && Average fitness:15.617146150208495\n",
            "-- Generation 10 --\n",
            " Max fitness:15.631798616266227 && Average fitness:15.619037900521112\n",
            "-- Generation 11 --\n",
            " Max fitness:15.633862343879992 && Average fitness:15.618453177697216\n",
            "-- Generation 12 --\n",
            " Max fitness:15.637301889902934 && Average fitness:15.624369196856673\n",
            "-- Generation 13 --\n",
            " Max fitness:15.646932618767165 && Average fitness:15.631179497982094\n",
            "-- Generation 14 --\n",
            " Max fitness:15.65931498444975 && Average fitness:15.634997394067558\n",
            "-- Generation 15 --\n",
            " Max fitness:15.688207171042453 && Average fitness:15.642667581698714\n",
            "-- Generation 16 --\n",
            " Max fitness:15.688207171042453 && Average fitness:15.654705992779009\n",
            "-- Generation 17 --\n",
            " Max fitness:15.688895080247041 && Average fitness:15.661894643966955\n",
            "-- Generation 18 --\n",
            " Max fitness:15.694398353883749 && Average fitness:15.67035592718339\n",
            "-- Generation 19 --\n",
            " Max fitness:15.695774172292928 && Average fitness:15.679436328683957\n",
            "-- Generation 20 --\n",
            " Max fitness:15.695774172292928 && Average fitness:15.689514198531176\n",
            "-- Generation 21 --\n",
            " Max fitness:15.695774172292928 && Average fitness:15.686693770792369\n",
            "-- Generation 22 --\n",
            " Max fitness:15.710220265589282 && Average fitness:15.692197044429074\n",
            "-- Generation 23 --\n",
            " Max fitness:15.706780719566343 && Average fitness:15.695017472167887\n",
            "-- Generation 24 --\n",
            " Max fitness:15.706780719566343 && Average fitness:15.697769108986233\n",
            "-- Generation 25 --\n",
            " Max fitness:15.708156537975519 && Average fitness:15.69518944946903\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 6 COMPLETED ----------------->\n",
            " Max fitness:15.712283993203046 && Average fitness:15.703031614401334\n",
            "7 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.580893335126685 && Average fitness:15.53982515561277\n",
            "-- Generation 2 --\n",
            " Max fitness:15.580893335126685 && Average fitness:15.557263653949082\n",
            "-- Generation 3 --\n",
            " Max fitness:15.604282248082692 && Average fitness:15.569439646870293\n",
            "-- Generation 4 --\n",
            " Max fitness:15.598778974445988 && Average fitness:15.582578712677929\n",
            "-- Generation 5 --\n",
            " Max fitness:15.598778974445988 && Average fitness:15.58787561355326\n",
            "-- Generation 6 --\n",
            " Max fitness:15.608409703310222 && Average fitness:15.59685282867314\n",
            "-- Generation 7 --\n",
            " Max fitness:15.608409703310222 && Average fitness:15.596027337627632\n",
            "-- Generation 8 --\n",
            " Max fitness:15.61253715853775 && Average fitness:15.60331917519627\n",
            "-- Generation 9 --\n",
            " Max fitness:15.620792068992815 && Average fitness:15.60840970331022\n",
            "-- Generation 10 --\n",
            " Max fitness:15.627671161038695 && Average fitness:15.609028821594356\n",
            "-- Generation 11 --\n",
            " Max fitness:15.629734888652461 && Average fitness:15.612227599395691\n",
            "-- Generation 12 --\n",
            " Max fitness:15.655875438426811 && Average fitness:15.617868454873314\n",
            "-- Generation 13 --\n",
            " Max fitness:15.654499620017635 && Average fitness:15.626536110851125\n",
            "-- Generation 14 --\n",
            " Max fitness:15.654499620017635 && Average fitness:15.630113238714983\n",
            "-- Generation 15 --\n",
            " Max fitness:15.655875438426811 && Average fitness:15.636510794317655\n",
            "-- Generation 16 --\n",
            " Max fitness:15.655875438426811 && Average fitness:15.637680239965453\n",
            "-- Generation 17 --\n",
            " Max fitness:15.661378712063518 && Average fitness:15.64641668686372\n",
            "-- Generation 18 --\n",
            " Max fitness:15.661378712063518 && Average fitness:15.652298310562955\n",
            "-- Generation 19 --\n",
            " Max fitness:15.661378712063518 && Average fitness:15.653123801608459\n",
            "-- Generation 20 --\n",
            " Max fitness:15.671009440927753 && Average fitness:15.657354443216676\n",
            "-- Generation 21 --\n",
            " Max fitness:15.671009440927753 && Average fitness:15.659280588989526\n",
            "-- Generation 22 --\n",
            " Max fitness:15.67857644217822 && Average fitness:15.663304857836362\n",
            "-- Generation 23 --\n",
            " Max fitness:15.680640169791989 && Average fitness:15.667329126683203\n",
            "-- Generation 24 --\n",
            " Max fitness:15.684767625019518 && Average fitness:15.67290119124037\n",
            "-- Generation 25 --\n",
            " Max fitness:15.680640169791989 && Average fitness:15.670011972581097\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 7 COMPLETED ----------------->\n",
            " Max fitness:15.695086263088342 && Average fitness:15.674552173331378\n",
            "8 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.583644971945052 && Average fitness:15.547529738704162\n",
            "-- Generation 2 --\n",
            " Max fitness:15.596027337627625 && Average fitness:15.564314723296116\n",
            "-- Generation 3 --\n",
            " Max fitness:15.61804043217446 && Average fitness:15.5811341033483\n",
            "-- Generation 4 --\n",
            " Max fitness:15.631798616266222 && Average fitness:15.59138395049666\n",
            "-- Generation 5 --\n",
            " Max fitness:15.631798616266222 && Average fitness:15.601736984025717\n",
            "-- Generation 6 --\n",
            " Max fitness:15.629734888652457 && Average fitness:15.60734344404311\n",
            "-- Generation 7 --\n",
            " Max fitness:15.634550253084575 && Average fitness:15.611918040253624\n",
            "-- Generation 8 --\n",
            " Max fitness:15.64349307274422 && Average fitness:15.621170419055336\n",
            "-- Generation 9 --\n",
            " Max fitness:15.638677708312102 && Average fitness:15.625469851584011\n",
            "-- Generation 10 --\n",
            " Max fitness:15.641429345130458 && Average fitness:15.627843138339838\n",
            "-- Generation 11 --\n",
            " Max fitness:15.644868891153399 && Average fitness:15.636442003397192\n",
            "-- Generation 12 --\n",
            " Max fitness:15.647620527971748 && Average fitness:15.637233098982467\n",
            "-- Generation 13 --\n",
            " Max fitness:15.65449962001763 && Average fitness:15.642667581698717\n",
            "-- Generation 14 --\n",
            " Max fitness:15.661378712063515 && Average fitness:15.6442841683295\n",
            "-- Generation 15 --\n",
            " Max fitness:15.668257804109397 && Average fitness:15.650440955710561\n",
            "-- Generation 16 --\n",
            " Max fitness:15.670321531723161 && Average fitness:15.655909833887033\n",
            "-- Generation 17 --\n",
            " Max fitness:15.686143443428685 && Average fitness:15.65814553880195\n",
            "-- Generation 18 --\n",
            " Max fitness:15.686143443428685 && Average fitness:15.66430232618301\n",
            "-- Generation 19 --\n",
            " Max fitness:15.694398353883743 && Average fitness:15.667501103984346\n",
            "-- Generation 20 --\n",
            " Max fitness:15.698525809111276 && Average fitness:15.680330610649918\n",
            "-- Generation 21 --\n",
            " Max fitness:15.696462081497508 && Average fitness:15.683460597530791\n",
            "-- Generation 22 --\n",
            " Max fitness:15.701277445929625 && Average fitness:15.6872097026958\n",
            "-- Generation 23 --\n",
            " Max fitness:15.701277445929625 && Average fitness:15.689582989451628\n",
            "-- Generation 24 --\n",
            " Max fitness:15.701277445929625 && Average fitness:15.692816162713195\n",
            "-- Generation 25 --\n",
            " Max fitness:15.706092810361746 && Average fitness:15.689445407610709\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 8 COMPLETED ----------------->\n",
            " Max fitness:15.706092810361746 && Average fitness:15.691474739764246\n",
            "9 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.602906429673512 && Average fitness:15.550075002761137\n",
            "-- Generation 2 --\n",
            " Max fitness:15.61804043217446 && Average fitness:15.572397656450017\n",
            "-- Generation 3 --\n",
            " Max fitness:15.623543705811167 && Average fitness:15.590833623132989\n",
            "-- Generation 4 --\n",
            " Max fitness:15.648996346380919 && Average fitness:15.605348507349802\n",
            "-- Generation 5 --\n",
            " Max fitness:15.639365617516681 && Average fitness:15.620929650833727\n",
            "-- Generation 6 --\n",
            " Max fitness:15.650372164790104 && Average fitness:15.632073779948053\n",
            "-- Generation 7 --\n",
            " Max fitness:15.65518752922221 && Average fitness:15.642048463414579\n",
            "-- Generation 8 --\n",
            " Max fitness:15.666881985700217 && Average fitness:15.644387354710185\n",
            "-- Generation 9 --\n",
            " Max fitness:15.666881985700217 && Average fitness:15.652642265165241\n",
            "-- Generation 10 --\n",
            " Max fitness:15.666881985700217 && Average fitness:15.658455097944014\n",
            "-- Generation 11 --\n",
            " Max fitness:15.671009440927747 && Average fitness:15.663992767040952\n",
            "-- Generation 12 --\n",
            " Max fitness:15.671697350132336 && Average fitness:15.66447430348416\n",
            "-- Generation 13 --\n",
            " Max fitness:15.677200623769039 && Average fitness:15.665402980910358\n",
            "-- Generation 14 --\n",
            " Max fitness:15.677200623769039 && Average fitness:15.664061557961407\n",
            "-- Generation 15 --\n",
            " Max fitness:15.694398353883747 && Average fitness:15.669220876995817\n",
            "-- Generation 16 --\n",
            " Max fitness:15.695086263088335 && Average fitness:15.67138779099027\n",
            "-- Generation 17 --\n",
            " Max fitness:15.695086263088335 && Average fitness:15.673726682285869\n",
            "-- Generation 18 --\n",
            " Max fitness:15.697837899906688 && Average fitness:15.673898659587019\n",
            "-- Generation 19 --\n",
            " Max fitness:15.701277445929628 && Average fitness:15.686384211650296\n",
            "-- Generation 20 --\n",
            " Max fitness:15.704029082747981 && Average fitness:15.691509135224479\n",
            "-- Generation 21 --\n",
            " Max fitness:15.709532356384688 && Average fitness:15.69604933597476\n",
            "-- Generation 22 --\n",
            " Max fitness:15.709532356384688 && Average fitness:15.697390758923703\n",
            "-- Generation 23 --\n",
            " Max fitness:15.712283993203041 && Average fitness:15.698628995491964\n",
            "-- Generation 24 --\n",
            " Max fitness:15.712283993203041 && Average fitness:15.702859637100179\n",
            "-- Generation 25 --\n",
            " Max fitness:15.712283993203041 && Average fitness:15.70602401944129\n",
            "-- Generation 26 --\n",
            "<-------------------ITERATION 9 COMPLETED ----------------->\n",
            " Max fitness:15.721226812862687 && Average fitness:15.70819093343574\n",
            "10 ITERATION \n",
            "-- Generation 1 --\n",
            " Max fitness:15.6035943388781 && Average fitness:15.550522143744121\n",
            "-- Generation 2 --\n",
            " Max fitness:15.6035943388781 && Average fitness:15.572776006512546\n",
            "-- Generation 3 --\n",
            " Max fitness:15.622855796606572 && Average fitness:15.594651519218454\n",
            "-- Generation 4 --\n",
            " Max fitness:15.622855796606572 && Average fitness:15.602700056912136\n",
            "-- Generation 5 --\n",
            " Max fitness:15.638677708312098 && Average fitness:15.612296390316141\n",
            "-- Generation 6 --\n",
            " Max fitness:15.651747983199275 && Average fitness:15.618315595856288\n",
            "-- Generation 7 --\n",
            " Max fitness:15.651747983199275 && Average fitness:15.628531047544422\n",
            "-- Generation 8 --\n",
            " Max fitness:15.651747983199275 && Average fitness:15.637095517141542\n",
            "-- Generation 9 --\n",
            " Max fitness:15.651747983199275 && Average fitness:15.64380263188628\n",
            "-- Generation 10 --\n",
            " Max fitness:15.675824805359861 && Average fitness:15.641291763289534\n",
            "-- Generation 11 --\n",
            " Max fitness:15.673073168541512 && Average fitness:15.6497874419662\n",
            "-- Generation 12 --\n",
            " Max fitness:15.673073168541512 && Average fitness:15.654912365540383\n",
            "-- Generation 13 --\n",
            " Max fitness:15.679264351382807 && Average fitness:15.664543094404625\n",
            "-- Generation 14 --\n",
            " Max fitness:15.696462081497513 && Average fitness:15.674139427808623\n",
            "-- Generation 15 --\n",
            " Max fitness:15.711596083998455 && Average fitness:15.684905206860432\n",
            "-- Generation 16 --\n",
            " Max fitness:15.711596083998455 && Average fitness:15.6942263765826\n",
            "-- Generation 17 --\n",
            " Max fitness:15.715035630021394 && Average fitness:15.697253177082795\n",
            "-- Generation 18 --\n",
            " Max fitness:15.718475176044336 && Average fitness:15.703341173543393\n",
            "-- Generation 19 --\n",
            " Max fitness:15.718475176044336 && Average fitness:15.703100405321788\n",
            "-- Generation 20 --\n",
            " Max fitness:15.746679453432453 && Average fitness:15.710839383873402\n",
            "-- Generation 21 --\n",
            " Max fitness:15.746679453432453 && Average fitness:15.713969370754285\n",
            "-- Generation 22 --\n",
            " Max fitness:15.758373909910452 && Average fitness:15.721467581084294\n",
            "-- Generation 23 --\n",
            " Max fitness:15.761813455933398 && Average fitness:15.72714283202215\n",
            "-- Generation 24 --\n",
            " Max fitness:15.758373909910452 && Average fitness:15.735707301619271\n",
            "-- Generation 25 --\n",
            " Max fitness:15.766628820365513 && Average fitness:15.747057803494974\n",
            "-- Generation 26 --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<-------------------ITERATION 10 COMPLETED ----------------->\n",
            " Max fitness:15.766628820365513 && Average fitness:15.748571203745069\n",
            "<------------------------- APOTELESMATA ------------------------>\n",
            "Avg for generations: 14.461538461538462\n",
            "Best fitness of best individual: 15.766628820365513\n",
            "Avg fitness of best individual: 15.734066902746786\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best solution of best individual: [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "population_size=20\n",
        "prob_cross = 0.6\n",
        "prob_mutation = 0.2\n",
        "genererations = 10\n",
        "\n",
        "averege_Fitness_all_gen=list()\n",
        "maxFitness_all_gen=list()\n",
        "Howmanygenerations =list()\n",
        "BestFitnessForAllGens =list()\n",
        "BestFitnessPerGens =list()\n",
        "BestFitness = list()\n",
        "genbest=list()\n",
        "best={}\n",
        "final_Bestfitness=list()\n",
        "X=[]\n",
        "\n",
        "def main(population_size,prob_cross,prob_mutation):\n",
        "  \n",
        "  \n",
        "  for i in range(10): # iterations\n",
        "      print(\"%d ITERATION \"%(i+1))\n",
        "\n",
        "       # dimiourgia plithismou\n",
        "      pop = toolbox.population(n=population_size)\n",
        "\n",
        "    #Evaluation fitness function \n",
        "      fitnesses = list(map(toolbox.evaluate, pop))\n",
        "      for ind, fit in zip(pop, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "   \n",
        "  \n",
        "    # CXPB pithanotita zeugaromatos\n",
        "    # MUTPB pithanotita metalakseis\n",
        "      CXPB, MUTPB = prob_cross, prob_mutation\n",
        "\n",
        "      #Statistics\n",
        "      stats = tools.Statistics(key=lambda ind:ind.fitness.values)\n",
        "      record = stats.compile(pop)\n",
        "      log = tools.Logbook()\n",
        "      log.record(gen=0, **record)\n",
        "\n",
        "\t# Extracting all the fitnesses of (epistrefi to fitness)\n",
        "      fits = [ind.fitness.values[0] for ind in pop]\n",
        "\t\n",
        "    # Variable keeping track of the number of generations\n",
        "    #metritis gia generation\n",
        "      generation=0\n",
        "      #Save to fitness pou exoume\n",
        "      previous_fit=max(fits)\n",
        "      #best fitness apo oles tis genies\n",
        "      bestfitness=0\n",
        "  #creteria \n",
        "      g = 1\n",
        "      critiria = False \n",
        "      max_g=50\n",
        "      fitness_unchanged = 0\n",
        "\n",
        "  # Begin the evolution\n",
        "      while critiria==False :\n",
        "        generation +=1\n",
        "\n",
        "    # A new generation\n",
        "        print(\"-- Generation %i --\" % generation) \n",
        "\n",
        "    # Select the next generation individuals\n",
        "        offspring = toolbox.select(pop, len(pop))\n",
        "    # Clone the selected individuals\n",
        "        offspring = list(map(toolbox.clone, offspring)) \n",
        "\n",
        "    # Apply crossover and mutation on the offspring\n",
        "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "            if random.random() < CXPB:\n",
        "                toolbox.mate(child1, child2)\n",
        "                del child1.fitness.values\n",
        "                del child2.fitness.values\n",
        "\n",
        "        for mutant in offspring:\n",
        "            if random.random() < MUTPB:\n",
        "                toolbox.mutate(mutant)\n",
        "                del mutant.fitness.values\n",
        "\n",
        "\n",
        "    # Evaluate the individuals with an invalid fitness\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "    # Replace the old population by the offspring\n",
        "        pop[:] = offspring\n",
        "\n",
        "    \n",
        "    # Gather all the fitnesses in one list and print the stats\n",
        "        fitness = [ind.fitness.values[0] for ind in pop]\n",
        "\n",
        "        record = stats.compile(pop)\n",
        "        log.record(gen=g, **record)  \n",
        "        best = log.select(\"max\")\n",
        "\n",
        "    #CRETERIA FOR WHILE LOOP(OSO TO TERM=FALSE trexei h while)\n",
        "        # reached max number of generations\n",
        "        if g >= max_g:\n",
        "            critiria = True\n",
        "            print(\"<-------------------ITERATION %d COMPLETED ----------------->\" %(i+1))\n",
        "        # best individual of gen is <1% better than best individual of previous gen\n",
        "        elif (g > 25) and max(fits) < (1.001*previous_fit):\n",
        "            critiria = True\n",
        "            print(\"<-------------------ITERATION %d COMPLETED ----------------->\" %(i+1))\n",
        "        # best individual of gen is same as best individual of previous gen\n",
        "        elif (g > 25) and previous_fit == max(fits):\n",
        "            fitness_unchanged += 1\n",
        "            #ean g>25 kai exw 5 fores stasimo fitness tote critiria=True\n",
        "            if fitness_unchanged >= 5:\n",
        "                critiria = True\n",
        "                print(\"<-------------------ITERATION %d COMPLETED ----------------->\" %(i+1))\n",
        "            else:\n",
        "                g += 1\n",
        "        # else continue\n",
        "        else:\n",
        "            fitness_unchanged = 0\n",
        "            g += 1\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "#------------------------------------EKTELESI GIA KATHE GENIA-----------------------------------------------------------------------------\n",
        "        #GIA KATHE GENERATION:\n",
        "        maxFitness_per_gen=(max(fitness))\n",
        "        average_fitness_per_gen = ((sum(fitness)/len(pop)))\n",
        "        print(\" Max fitness:%s && Average fitness:%s\" %((maxFitness_per_gen),(average_fitness_per_gen)))\n",
        "    \n",
        "\n",
        "#--------------------------------------TO MEGALITERO KATHE GENIAS KAI TO ANTISTOIXO AVG ----------------------------------------------------------------------\n",
        "        maxFitness_all_gen.append(maxFitness_per_gen)\n",
        "        averege_Fitness_all_gen.append(average_fitness_per_gen)\n",
        "\n",
        "        #TWRA THELOUME APO OLES TIS GENIES NA KRATISOUME MONO ENA, TO MEGALITERO \n",
        "        final_Bestfitness.append(max(maxFitness_all_gen))\n",
        "\n",
        "#----------------------------------------------SUNOLIKES GENIES EKTELESIS---------------------------------------------------------------------------------\n",
        "        Howmanygenerations.append(g)\n",
        "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "        #PREPEI NA VROUME TO BEST FITNESS \n",
        "        best_fitness =max(fitness)\n",
        "        if best_fitness > bestfitness:\n",
        "            bestfitness = best_fitness\n",
        "            Bestindex =pop[fitness.index(best_fitness)]\n",
        "        BestFitnessPerGens.append(best_fitness)\n",
        "\n",
        "         \n",
        "        #Vale stin lista mono to megalutero stoixio pou vrikes\n",
        "        BestFitnessForAllGens.append(max(BestFitnessPerGens))\n",
        "        X.append(mean(BestFitnessPerGens))\n",
        "#################################################################################\n",
        "      \n",
        "\n",
        "################################################################################ \n",
        "\n",
        "  best_ind =tools.selBest(pop,1)[0]\n",
        "  print(\"<------------------------- APOTELESMATA ------------------------>\")\n",
        "  print(\"Avg for generations:\",mean(Howmanygenerations))\n",
        "  print(\"Best fitness of best individual:\",np.amax(max(BestFitnessForAllGens)))\n",
        "  print(\"Avg fitness of best individual:\",np.mean(BestFitnessForAllGens))\n",
        "\n",
        "\n",
        "  plt.figure(0)\n",
        "  plt.subplot(2, 2, 1)\n",
        "  plt.plot(BestFitnessForAllGens,color='red')\n",
        "  plt.title(\"MAX\")\n",
        "  plt.ylabel(\"Max fitness\")\n",
        "  plt.xlabel(\"Generation\")\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(2, 2, 2)\n",
        "  plt.plot(X,color=\"green\")\n",
        "  plt.title(\"AVG\")\n",
        "  plt.ylabel(\"Avg fitness\")\n",
        "  plt.xlabel(\"Generation\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Best solution of best individual:\",(best_ind))\n",
        "\n",
        "  return best_ind\n",
        " \n",
        "keep = main(population_size,prob_cross,prob_mutation)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dYaYp4GeFPUo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "tf_idf_Xtrain=tf_idf_Xtrain[:8251]\n",
        "labels_fnames = [\n",
        "            'train-label.dat',\n",
        "            ]\n",
        "y = pd.read_csv(labels_fnames[0] , delimiter = ' ', header = None)\n",
        "\n",
        "\n",
        "clean_doc = []\n",
        "wordfreq = {}\n",
        "for doc in file:\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    for token in tokens:\n",
        "        if token not in wordfreq.keys():\n",
        "            wordfreq[token] = 1\n",
        "        else:\n",
        "            wordfreq[token] += 1\n",
        "            \n",
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist()\n",
        "\n",
        "sentence_vectors = []\n",
        "for doc in file:\n",
        "    doc_tokens = nltk.word_tokenize(doc)\n",
        "    vec = []\n",
        "    for token in wordfreq:\n",
        "        if token in doc_tokens:\n",
        "            count = 0\n",
        "            for tok in doc_tokens:\n",
        "                if tok == token:\n",
        "                    count += 1\n",
        "            vec.append(count)\n",
        "        else:\n",
        "            vec.append(0)\n",
        "    sentence_vectors.append(vec)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkLKPx6YFPUp",
        "outputId": "d34568aa-f9de-4977-bec5-fee3f7bc1375"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8251, 8522)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train =np.array(sentence_vectors)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj3oO9LyFPUq",
        "outputId": "9c103c61-6806-4f67-c264-ab8ecf77061e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5775, 8522) (2476, 8522) (5775, 20) (2476, 20)\n"
          ]
        }
      ],
      "source": [
        "X_train.shape\n",
        "for i in range(len(keep)):\n",
        "    if keep[i] == 0:\n",
        "        X_train[:,i] = 0\n",
        "        \n",
        "       \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, y, test_size=0.3, random_state=0)  \n",
        "\n",
        "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkgvFzRHFPUr",
        "outputId": "29985254-b8ea-4afd-e60f-2f39f03b1a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5775, 7565) (2476, 7565) (5775, 20) (2476, 20)\n"
          ]
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_minmax = scaler.fit_transform(X_train)\n",
        "X_test_minmax=scaler.fit_transform(X_test)\n",
        "X_train_minmax=X_train[:,:-957]\n",
        "X_test_minmax=X_test[:,:-957]\n",
        "print(X_train_minmax.shape,X_test_minmax.shape,Y_train.shape,Y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "n0RrA-HGFPUs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "model = tf.keras.models.load_model(\"ce.h5\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_qGEDqcFPUt",
        "outputId": "94d5e94f-a481-4e53-e6b3-876633004c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1853 - accuracy: 0.3922\n",
            "Epoch 2/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1828 - accuracy: 0.3919\n",
            "Epoch 3/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1811 - accuracy: 0.3995\n",
            "Epoch 4/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.3929\n",
            "Epoch 5/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.3938\n",
            "Epoch 6/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.3969\n",
            "Epoch 7/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1749 - accuracy: 0.3988\n",
            "Epoch 8/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.3960\n",
            "Epoch 9/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1724 - accuracy: 0.4010\n",
            "Epoch 10/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1708 - accuracy: 0.4029\n",
            "Epoch 11/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1685 - accuracy: 0.4010\n",
            "Epoch 12/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1676 - accuracy: 0.4055\n",
            "Epoch 13/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1652 - accuracy: 0.4005\n",
            "Epoch 14/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1640 - accuracy: 0.4088\n",
            "Epoch 15/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1632 - accuracy: 0.4057\n",
            "Epoch 16/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1622 - accuracy: 0.4031\n",
            "Epoch 17/30\n",
            "181/181 [==============================] - 1s 7ms/step - loss: 0.1597 - accuracy: 0.4033\n",
            "Epoch 18/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1584 - accuracy: 0.4087\n",
            "Epoch 19/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1577 - accuracy: 0.4061\n",
            "Epoch 20/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1553 - accuracy: 0.4107\n",
            "Epoch 21/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1537 - accuracy: 0.4137\n",
            "Epoch 22/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1531 - accuracy: 0.4083\n",
            "Epoch 23/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1507 - accuracy: 0.4102\n",
            "Epoch 24/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1485 - accuracy: 0.4144\n",
            "Epoch 25/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1470 - accuracy: 0.4147\n",
            "Epoch 26/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1456 - accuracy: 0.4144\n",
            "Epoch 27/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1451 - accuracy: 0.4154\n",
            "Epoch 28/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1431 - accuracy: 0.4149\n",
            "Epoch 29/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1414 - accuracy: 0.4159\n",
            "Epoch 30/30\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.1417 - accuracy: 0.4140\n",
            "78/78 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.2322\n",
            "Accuracy for  retrained model is 0.23222939670085907\n",
            "Lose for retrained model is  0.3881796896457672\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train_minmax,Y_train, epochs=30 , verbose=1)\n",
        "losse1,accuracy1=model.evaluate(X_test_minmax,Y_test)\n",
        "print(\"Accuracy for  retrained model is\", accuracy1)\n",
        "print(\"Lose for retrained model is \",losse1)\n",
        "\n",
        "#loss2, accuracy2 = model.evaluate(X_test_minmax, Y_test, verbose=0)\n",
        "#print(\"Accuracy for  retrained model is\", accuracy2)\n",
        "#print(\"Lose for retrained model is \",loss2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MyqE1BrIFPUt"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "moNYpuITFPUu"
      },
      "outputs": [],
      "source": [
        "labels_fnames = [\n",
        "            'test-label.dat'\n",
        "            ]\n",
        "Y_test= pd.read_csv(labels_fnames[0] ,nrows=2476,delimiter = ' ', header = None)\n",
        "\n",
        "#TEST-DATA\n",
        "path = 'test-data.dat'\n",
        "\n",
        "clean_files = []\n",
        "df = pd.DataFrame()\n",
        "\n",
        "file = open(path).readlines()\n",
        "len(file)\n",
        "\n",
        "clean_docc = []\n",
        "wordfreqq = {}\n",
        "for doc in file:\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    for token in tokens:\n",
        "        if token not in wordfreqq.keys():\n",
        "            wordfreqq[token] = 1\n",
        "        else:\n",
        "            wordfreqq[token] += 1\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "fdist = FreqDist()\n",
        "sentence_vectorss = []\n",
        "for doc in file:\n",
        "    doc_tokens = nltk.word_tokenize(doc)\n",
        "    vecc = []\n",
        "    for token in wordfreqq:\n",
        "        if token in doc_tokens:\n",
        "            count = 0\n",
        "            for tok in doc_tokens:\n",
        "                if tok == token:\n",
        "                    count += 1\n",
        "            vecc.append(count)\n",
        "        else:\n",
        "            vecc.append(0)\n",
        "    sentence_vectorss.append(vecc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Co3lBkrFPUu",
        "outputId": "d9cdf8fd-5804-497e-9053-fb2ee0435cc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2476, 20)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test =np.array(sentence_vectorss)\n",
        "X_test_new=scaler.fit_transform(X_test)\n",
        "X_test_new=X_test[:-1507,:-638]\n",
        "Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1rwmImvihiO",
        "outputId": "735de6e8-8d18-4140-97e9-9ba0c1c4b41c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for non retrained model is 0.10945072770118713\n",
            "loss for non retrained model is 0.700946569442749\n"
          ]
        }
      ],
      "source": [
        "# Firstly, we dont retrain the ANN.\n",
        "loss, accuracy = model.evaluate(X_test_new, Y_test, verbose=0)\n",
        "print(\"Accuracy for non retrained model is\", accuracy)\n",
        "print(\"loss for non retrained model is\", loss)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq2E0wI8iw4G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "my_final_ga.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
